import streamlit as st
import requests
from bs4 import BeautifulSoup
import urllib.parse
import pandas as pd
import time
import io
import gspread
from google.oauth2 import service_account
from googleapiclient.discovery import build

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="JW Library Search",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main {
        background-color: #f8f9fa;
    }
    .stApp {
        font-family: 'Roboto', sans-serif;
    }
    .search-result {
        background-color: white;
        border-radius: 10px;
        padding: 20px;
        margin-bottom: 15px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        transition: transform 0.2s;
    }
    .search-result:hover {
        transform: translateY(-3px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    }
    .result-title {
        color: #1f77b4;
        font-weight: bold;
        font-size: 18px;
        margin-bottom: 5px;
    }
    .result-publication {
        color: #777;
        font-size: 14px;
        font-style: italic;
        margin-bottom: 8px;
    }
    .result-snippet {
        color: #333;
        font-size: 15px;
        line-height: 1.5;
    }
    .placeholder {
        background: linear-gradient(90deg, #f2f2f2 25%, #e6e6e6 50%, #f2f2f2 75%);
        background-size: 200% 100%;
        animation: loading 1.5s infinite;
        border-radius: 4px;
        height: 100px;
        margin-bottom: 15px;
    }
    @keyframes loading {
        0% {
            background-position: 200% 0;
        }
        100% {
            background-position: -200% 0;
        }
    }
    .sidebar-header {
        margin-bottom: 30px;
    }
    .google-sheet-section {
        background-color: #f0f7ff;
        border-radius: 10px;
        padding: 15px;
        margin-top: 20px;
        border-left: 5px solid #4285F4;
    }
</style>
""", unsafe_allow_html=True)

# ------------------------------
# â‘  è¨€èªã«åˆã‚ã›ãŸãƒ™ãƒ¼ã‚¹URLã®è¨­å®š
# ------------------------------
def get_base_url(lang):
    """
    è¨€èªã”ã¨ã«ãƒ™ãƒ¼ã‚¹URLã‚’è¿”ã—ã¾ã™ã€‚
    æ—¥æœ¬èªã®å ´åˆ: "https://wol.jw.org/ja/wol/s/r7/lp-j"
    è‹±èªã®å ´åˆ:   "https://wol.jw.org/en/wol/s/r1/lp-e"
    """
    urls = {
        "ja": "https://wol.jw.org/ja/wol/s/r7/lp-j",
        "en": "https://wol.jw.org/en/wol/s/r1/lp-e"
    }
    # æŒ‡å®šã•ã‚ŒãŸè¨€èªãŒç„¡ã„å ´åˆã¯æ—¥æœ¬èªç‰ˆã‚’è¿”ã™
    return urls.get(lang, urls["ja"])

# ------------------------------
# â‘¡ æ¤œç´¢å‡¦ç†ï¼ˆãƒšãƒ¼ã‚¸å˜ä½ã§yieldï¼‰
# ------------------------------
def _fetch_and_parse_page(keyword, page_num, lang="ja", sort="occ"):
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ãƒšãƒ¼ã‚¸ç•ªå·ã€è¨€èªã€ã‚½ãƒ¼ãƒˆé †ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã€
    çµæœï¼ˆã‚¿ã‚¤ãƒˆãƒ«ï¼ãƒªãƒ³ã‚¯ï¼ã‚¹ãƒ‹ãƒšãƒƒãƒˆï¼å‡ºç‰ˆç‰©æƒ…å ±ï¼‰ã®ãƒªã‚¹ãƒˆã¨æ¬¡ãƒšãƒ¼ã‚¸ã®æœ‰ç„¡ã‚’è¿”ã—ã¾ã™ã€‚
    """
    base_url = get_base_url(lang)
    params = {
        "q": keyword,
        "st": "a",
        "p": "par",
        "r": sort,
        "pg": str(page_num),
    }
    
    try:
        response = requests.get(base_url, params=params)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
        
        items = []
        # æ—§å½¢å¼ã®å ´åˆï¼ˆul.results.resultContentDocumentï¼‰
        result_blocks = soup.select("ul.results.resultContentDocument")
        # ã‚«ãƒ¼ãƒ‰å½¢å¼ã®å ´åˆã¯ li.navCard ã‚’å¯¾è±¡
        if not result_blocks:
            result_blocks = soup.select("li.navCard")
        
        for rb in result_blocks:
            # ã€ã‚±ãƒ¼ã‚¹1ã€‘æ—§å½¢å¼
            caption_li = rb.select_one("li.caption")
            if caption_li:
                link_tag = caption_li.select_one("a.lnk")
                if link_tag:
                    title = link_tag.get_text(strip=True)
                    # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾URLã«å¤‰æ›
                    link = urllib.parse.urljoin(base_url, link_tag.get("href", "").strip())
                else:
                    title, link = "", ""
                snippet_li = rb.select_one("li.searchResult")
                if snippet_li:
                    doc_div = snippet_li.select_one("div.document")
                    snippet = doc_div.get_text(" ", strip=True) if doc_div else ""
                else:
                    snippet = ""
                publication = ""
            # ã€ã‚±ãƒ¼ã‚¹2ã€‘ã‚«ãƒ¼ãƒ‰å½¢å¼
            elif rb.select_one("div.cardTitleBlock"):
                title_div = rb.select_one("div.cardLine1")
                title = title_div.get_text(strip=True) if title_div else ""
                alt_title_div = rb.select_one("div.cardLine2")
                if not title and alt_title_div:
                    title = alt_title_div.get_text(strip=True)
                link_tag = rb.select_one("a")
                if link_tag:
                    link = urllib.parse.urljoin(base_url, link_tag.get("href", "").strip())
                else:
                    link = ""
                snippet = ""
                detail_div = rb.select_one("div.cardTitleDetail")
                publication = detail_div.get_text(strip=True) if detail_div else ""
            else:
                title, link, snippet, publication = "", "", "", ""
            
            if title and link:  # æœ‰åŠ¹ãªçµæœã®ã¿è¿½åŠ 
                items.append({
                    "title": title,
                    "link": link,
                    "snippet": snippet,
                    "publication": publication
                })
        
        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã®å–å¾—ï¼ˆè©²å½“è¦ç´ ãŒç„¡ã‘ã‚Œã°æ¬¡ãƒšãƒ¼ã‚¸ç„¡ã—ã¨åˆ¤æ–­ï¼‰
        try:
            total_str = soup.select_one("#searchResultsTotal")["value"]
            page_size_str = soup.select_one("#searchResultsPageSize")["value"]
            current_page_str = soup.select_one("#searchResultsPageNumber")["value"]
            total = int(total_str)
            page_size = int(page_size_str)
            current_page = int(current_page_str)
            total_pages = (total + page_size - 1) // page_size
            has_next = (current_page < total_pages)
            result_info = {
                "total": total,
                "current_page": current_page,
                "total_pages": total_pages
            }
        except (TypeError, KeyError):
            has_next = False
            result_info = {
                "total": len(items),
                "current_page": 1,
                "total_pages": 1
            }
        
        return {"items": items, "has_next": has_next, "result_info": result_info}
    
    except Exception as e:
        st.error(f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return {"items": [], "has_next": False, "result_info": {"total": 0, "current_page": 1, "total_pages": 1}}

# ------------------------------
# Google Sheets é€£æºæ©Ÿèƒ½
# ------------------------------
def connect_to_google_sheets(json_key_content):
    """
    Google Sheetsã¸ã®APIæ¥ç¶š
    """
    try:
        # èªè¨¼æƒ…å ±ã‚’JSONã‹ã‚‰èª­ã¿è¾¼ã‚€
        credentials = service_account.Credentials.from_service_account_info(
            json_key_content,
            scopes=[
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive"
            ]
        )
        
        # Google Sheets APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
        gc = gspread.authorize(credentials)
        sheets_api = build('sheets', 'v4', credentials=credentials)
        
        return gc, sheets_api
    except Exception as e:
        st.error(f"Google Sheetsã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None, None

def get_or_create_sheet(gc, sheet_name, worksheet_name=None):
    """
    æŒ‡å®šã—ãŸã‚·ãƒ¼ãƒˆã‚’å–å¾—ã™ã‚‹ã‹ã€å­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆã—ã¾ã™
    """
    try:
        # ã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        try:
            sh = gc.open(sheet_name)
        except gspread.exceptions.SpreadsheetNotFound:
            # ã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆ
            sh = gc.create(sheet_name)
            # ä½œæˆè€…ã«ç·¨é›†æ¨©é™ã‚’ä»˜ä¸
            sh.share(gc.auth.service_account_email, role='writer', perm_type='user')
        
        # ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚’å–å¾—ã¾ãŸã¯ä½œæˆ
        if worksheet_name:
            try:
                worksheet = sh.worksheet(worksheet_name)
            except gspread.exceptions.WorksheetNotFound:
                worksheet = sh.add_worksheet(title=worksheet_name, rows=100, cols=20)
        else:
            worksheet = sh.sheet1
        
        return sh, worksheet
    except Exception as e:
        st.error(f"ã‚·ãƒ¼ãƒˆã®å–å¾—ã¾ãŸã¯ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None, None

def export_to_google_sheets(gc, data, sheet_name, worksheet_name=None):
    """
    æ¤œç´¢çµæœã‚’Google Sheetsã«å‡ºåŠ›ã—ã¾ã™
    """
    try:
        # ã‚·ãƒ¼ãƒˆã‚’å–å¾—ã¾ãŸã¯ä½œæˆ
        sh, worksheet = get_or_create_sheet(gc, sheet_name, worksheet_name)
        if not sh or not worksheet:
            return False, "ã‚·ãƒ¼ãƒˆã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ"
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
        df = pd.DataFrame(data)
        headers = df.columns.tolist()
        values = [headers] + df.values.tolist()
        
        # ã‚·ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿
        worksheet.clear()
        worksheet.update(values)
        
        # è¡¨ç¤ºã®èª¿æ•´
        worksheet.format('A1:Z1', {
            "backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9},
            "horizontalAlignment": "CENTER",
            "textFormat": {"bold": True}
        })
        
        return True, f"ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ¼ãƒˆ '{sheet_name} / {worksheet.title}' ã«æ­£å¸¸ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ"
    except Exception as e:
        return False, f"Google Sheetsã¸ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"

# ------------------------------
# Streamlit UIå‡¦ç†
# ------------------------------
def display_search_result(item):
    """æ¤œç´¢çµæœã®1é …ç›®ã‚’è¡¨ç¤ºã™ã‚‹"""
    st.markdown(f"""
    <div class="search-result">
        <div class="result-title">{item['title']}</div>
        <div class="result-publication">{item['publication']}</div>
        <div class="result-snippet">{item['snippet']}</div>
        <a href="{item['link']}" target="_blank">è¨˜äº‹ã‚’èª­ã‚€</a>
    </div>
    """, unsafe_allow_html=True)

def display_loading_animation(num_placeholders=3):
    """ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’è¡¨ç¤º"""
    loading_container = st.container()
    with loading_container:
        for _ in range(num_placeholders):
            st.markdown('<div class="placeholder"></div>', unsafe_allow_html=True)
    return loading_container

# ------------------------------
# Streamlitã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³éƒ¨åˆ†
# ------------------------------
def main():
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'google_sheets_connected' not in st.session_state:
        st.session_state.google_sheets_connected = False
    if 'gc' not in st.session_state:
        st.session_state.gc = None
    if 'all_results' not in st.session_state:
        st.session_state.all_results = []
        
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.markdown('<div class="sidebar-header"></div>', unsafe_allow_html=True)
        st.image("https://assetsnffrgf-a.akamaihd.net/assets/m/802013135/univ/art/802013135_univ_lsr_xl.jpg", width=200)
        st.markdown("## JW Library Search")
        st.markdown("---")
        
        # æ¤œç´¢è¨­å®š
        keyword = st.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", placeholder="ä¾‹: è–æ›¸, ä¿¡ä»°, å¸Œæœ›...")
        lang = st.selectbox("è¨€èªã‚’é¸æŠ", ["ja", "en"], format_func=lambda x: "æ—¥æœ¬èª" if x == "ja" else "English")
        sort_options = {
            "newest": "æœ€æ–°é †",
            "occ": "é–¢é€£æ€§é †"
        }
        sort = st.selectbox("ä¸¦ã³é †", list(sort_options.keys()), format_func=lambda x: sort_options[x])
        max_pages = st.slider("æœ€å¤§å–å¾—ãƒšãƒ¼ã‚¸æ•°", 1, 10, 3)
        
        search_button = st.button("æ¤œç´¢", use_container_width=True)
        
        st.markdown("---")
        st.markdown("### ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        
        # ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if 'all_results' in st.session_state and len(st.session_state.all_results) > 0:
            export_format = st.selectbox("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼", ["CSV", "Excel"])
            
            if st.button("æ¤œç´¢çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", use_container_width=True):
                df = pd.DataFrame(st.session_state.all_results)
                
                if export_format == "CSV":
                    csv = df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=csv,
                        file_name=f"search_results_{keyword}_{lang}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
                else:  # Excel
                    # Excelãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚¤ãƒŠãƒªã‚¹ãƒˆãƒªãƒ¼ãƒ ã¨ã—ã¦ä½œæˆ
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df.to_excel(writer, index=False, sheet_name='æ¤œç´¢çµæœ')
                    
                    # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦èª­ã¿å–ã‚Š
                    output.seek(0)
                    excel_data = output.read()
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    st.download_button(
                        label="Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=excel_data,
                        file_name=f"search_results_{keyword}_{lang}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )

        # Google Sheetsé€£æº
        st.markdown("---")
        with st.expander("Google Sheetsé€£æº", expanded=False):
            if not st.session_state.google_sheets_connected:
                st.markdown("### Google Sheetsã«æ¥ç¶š")
                st.markdown("""
                1. Google Cloud Consoleã§ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆ
                2. ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®JSONã‚­ãƒ¼ã‚’å–å¾—
                3. JSONã‚­ãƒ¼ã®å†…å®¹ã‚’ä»¥ä¸‹ã«è²¼ã‚Šä»˜ã‘
                """)
                json_key = st.text_area("ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®JSONã‚­ãƒ¼", height=100, 
                                     placeholder='{  "type": "service_account",  "project_id": "...",  ... }')
                
                if st.button("æ¥ç¶š", key="connect_google"):
                    try:
                        # JSONã®æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
                        import json
                        json_key_content = json.loads(json_key)
                        
                        # Google Sheetsã«æ¥ç¶š
                        gc, sheets_api = connect_to_google_sheets(json_key_content)
                        if gc and sheets_api:
                            st.session_state.gc = gc
                            st.session_state.sheets_api = sheets_api
                            st.session_state.google_sheets_connected = True
                            st.success("Google Sheetsã«æ­£å¸¸ã«æ¥ç¶šã—ã¾ã—ãŸï¼")
                    except json.JSONDecodeError:
                        st.error("JSONã‚­ãƒ¼ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚æ­£ç¢ºãªJSONã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚")
                    except Exception as e:
                        st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
            else:
                st.success("Google Sheetsã«æ¥ç¶šæ¸ˆã¿ã§ã™")
                
                if 'all_results' in st.session_state and len(st.session_state.all_results) > 0:
                    st.markdown("### Google Sheetsã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
                    sheet_name = st.text_input("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå", "JWæ¤œç´¢çµæœ")
                    worksheet_name = st.text_input("ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆå", "æ¤œç´¢çµæœ")
                    
                    if st.button("Google Sheetsã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", key="export_google"):
                        success, message = export_to_google_sheets(
                            st.session_state.gc, 
                            st.session_state.all_results, 
                            sheet_name, 
                            worksheet_name
                        )
                        if success:
                            st.success(message)
                        else:
                            st.error(message)
                
                if st.button("æ¥ç¶šã‚’è§£é™¤", key="disconnect_google"):
                    st.session_state.gc = None
                    st.session_state.sheets_api = None
                    st.session_state.google_sheets_connected = False
                    st.info("Google Sheetsã¨ã®æ¥ç¶šã‚’è§£é™¤ã—ã¾ã—ãŸ")

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢
    st.title("JW Library Search Tool")
    
    # æ¤œç´¢å®Ÿè¡Œ
    if search_button and keyword:
        st.session_state.all_results = []  # çµæœã‚’ãƒªã‚»ãƒƒãƒˆ
        
        # æ¤œç´¢é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        st.info(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{keyword}ã€ã§æ¤œç´¢ã‚’é–‹å§‹ã—ã¾ã™...")
        
        # ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³è¡¨ç¤º
        loading = display_loading_animation()
        
        # æ¤œç´¢å®Ÿè¡Œ
        page_num = 1
        total_pages = max_pages  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        
        while page_num <= max_pages:
            # æ¤œç´¢ã‚’å®Ÿè¡Œ
            page_data = _fetch_and_parse_page(keyword, page_num, lang=lang, sort=sort)
            
            # çµæœã‚’ä¿å­˜
            st.session_state.all_results.extend(page_data["items"])
            
            # åˆè¨ˆãƒšãƒ¼ã‚¸æ•°ã‚’æ›´æ–°
            if page_num == 1:
                total_pages = min(max_pages, page_data["result_info"]["total_pages"])
                if total_pages == 0:
                    break
            
            # é€²æ—çŠ¶æ³ã‚’è¡¨ç¤º
            progress = page_num / total_pages
            st.progress(progress)
            
            # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒãªã‘ã‚Œã°çµ‚äº†
            if not page_data["has_next"]:
                break
                
            page_num += 1
            time.sleep(0.5)  # ã‚µãƒ¼ãƒãƒ¼è² è·ã‚’è€ƒæ…®

        # ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’éè¡¨ç¤º
        loading.empty()
        
        # æ¤œç´¢çµæœæ¦‚è¦
        if len(st.session_state.all_results) > 0:
            st.success(f"æ¤œç´¢å®Œäº†ï¼ {len(st.session_state.all_results)} ä»¶ã®çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
        else:
            st.warning("æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚")
    
    # æ¤œç´¢çµæœã®è¡¨ç¤º
    if 'all_results' in st.session_state and len(st.session_state.all_results) > 0:
        # çµæœãƒªã‚¹ãƒˆã‚’DataFrameã«å¤‰æ›
        df = pd.DataFrame(st.session_state.all_results)
        
        # ã‚¿ãƒ–ã§è¡¨ç¤ºæ–¹æ³•ã‚’åˆ‡ã‚Šæ›¿ãˆ
        tab1, tab2 = st.tabs(["ã‚«ãƒ¼ãƒ‰è¡¨ç¤º", "ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º"])
        
        with tab1:
            # ã‚«ãƒ¼ãƒ‰è¡¨ç¤º
            for item in st.session_state.all_results:
                display_search_result(item)
        
        with tab2:
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
            st.dataframe(
                df[["title", "publication", "link"]],
                column_config={
                    "title": "ã‚¿ã‚¤ãƒˆãƒ«",
                    "publication": "å‡ºç‰ˆç‰©",
                    "link": st.column_config.LinkColumn("ãƒªãƒ³ã‚¯")
                },
                hide_index=True,
                use_container_width=True
            )
    elif not keyword:
        st.info("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã€æ¤œç´¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()